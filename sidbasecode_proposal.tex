\documentclass[10pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{url}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{float}
\usepackage{lipsum}
\usepackage{multicol}
\usepackage{xcolor}
\usepackage{natbib}
\usepackage[font=small]{caption}
\addtolength{\abovecaptionskip}{-3mm}
\addtolength{\textfloatsep}{-5mm}
\setlength\columnsep{20pt}

\usepackage[a4paper,left=1.50cm, right=1.50cm, top=1.50cm, bottom=1.50cm]{geometry}

\author{Josh Bailey <josh@vandervecken.com>}

\title{Sequencing the Chiptune Genome}

\begin{document}

        \begin{center}
          {\Large \textbf{Sequencing the Chiptune Genome}}\\
                \vspace{1em}
                Proposal for Thesis\\
                \vspace{1em}
                \textit{
                Ph.D. Student (Music) - Josh Bailey,
                Student Number: 300665818\\
                  New Zealand School of Music—Te Kōkī,
                  Victoria University of Wellington}\\
                \vspace{1em}
                Supervisors\\
                \vspace{1em}
                \textit{
                  Jim Murphy, Victoria University of Wellington\\
                  Dugal McKinnon, Victoria University of Wellington\\
                  Tom White, Victoria University of Wellington}\\
        \end{center}

        \begin{center}
                \rule{150mm}{0.2mm}
        \end{center}

        \begin{abstract}
          A computational musicological analysis of all known musical
          performances (from the curated High Voltage SID collection
          including over 55,000 performances) on the Commodore 64
          computer platform.  The analysis will identify and attribute
          innovation in expressive techniques in the form of machine
          language programs that produce unique timbres - metaphorical
          DNA - to composers.

          Contemporary machine learning techniques will be used on
          decompiled Commodore 64 performances (which are realized in
          the form of complete machine language programs). The
          Commodore 64 platform is chosen as it is simple enough to
          make an exhaustive study of performances, while still being
          sonically capable (including a 3 voice, multiple waveform
          synthesizer with basic FM and filter features).  The analysis
          will operate directly on low level synthesizer machine language
          commands rather than audio samples (both simplifying the
          analysis while achieving an exact description of musical
          expression).

          As well as enumerating the evolution of musical expression,
          the analysis will produce a dataset and machine learning
          tools that can identify the use of specific techniques in a
          given performance (whether machine or human generated),
          which may serve to advance current discussions around the
          role of machine learning in composition. The tools and
          concepts may also be transferable to less constrained
          systems in future work.
         \end{abstract}

        \begin{center}
                \rule{150mm}{0.2mm}
        \end{center}

        \vspace{5mm}

\begin{multicols*}{2}

  \section{Introduction}
  At first glance musicological analysis of Commodore 64 music might
  appear trivial as the hardware is simple and well documented. Its
  value as a research platform is the sound hardware's (Sound
  Interface Device or SID chip) essential resemblance to synthesizers
  today (multiple voices, waveforms, and filters), combined with a
  history of expressive innovation arising from its constraints (for
  example, PCM sample playback despite the hardware not being designed
  with that capability).

  SID chip programming involves sequences of changes to memory
  registers at controlled intervals. These sequences are analogous to
  DNA - a given performance will include sequences programmed by a
  composer, either of their own invention (including re-sequencing
  from another performance that might use similar patches), or
  sequences recovered from the work of others.

  These ``DNA'' sequences can then be indexed across all known
  performances, allowing for variation (both variations that produce
  the same audio output, and variations that produce slightly or
  vastly different output depending on the precise order in which they
  are executed). Also like DNA, these sequences can be recombined and
  edited to produce new sequences, compared between sequences, and a
  given subsequence's effect on audio output can be determined.

  The proposal aims to make a systematic study of all known SID
  programming sequences (as represented in the High Voltage SID
  Collection), which will include methods for identifying the same or
  similar programming techniques across all performances. Since the
  collection includes composer names and dates for most performances,
  it will be possible to realize an evolutionary timeline of
  techniques.

  The HVSC collection also contains some performances which have not
  yet been attributed to a composer. It is proposed to develop tools
  can analyze these performances (or indeed any new performance) and
  determine the similarity of the techniques used to other
  performances (in other words, suggesting a likely composer, or the
  composers used in the training set of a generative music system).

  Machine learning classification technology will form the basis of
  the analysis. While the goal of this research is a musicological,
  inevitably the potential for the same machine learning technology to
  create performances is realized. The proposal will necessarily
  engage with this possibility to demonstrate the practicality of
  identifying the original performances in the tools' training
  set. The goal is to identify techniques in all performances whether
  directly from human composers or indirectly via generative tools.

  \section{Background}

  \subsection{Contemperaneous platforms}
  The Commodore 64 is not the only platform of the period, but is
  chosen because it is unique in its expressibility for the time and
  having significant capabilities built in without the user having to
  add additional harware. For example, a competing platform of the
  period was the ZX Spectrum. This system had only a built in
  ``beep''er speaker with no filters or additional waveforms (though
  additional hardware was available adding among other features
  FM synthesis). The NES platform, like the SID chip had multiple
  waveforms and voices, but no filters.

  \subsection{SID players}
  A Commodore 64 musical performance is mostly commonly realized as a
  machine language program that programs the SID chip, packaged as a
  SID file. To hear a performance a complete Commodore 64 environment
  (or an emulated environment) therefore is necessary. A SID player
  executes a SID file (typically in an emulator within the player,
  including an emulated SID chip or chips), producing audio samples.
  The VICE emulator includes a SID player, which includes diagnostic
  logging of all commands sent to the SID chip.

  \subsection{High Voltage SID Collection}
  The High Voltage SID collection is a large, community curated
  collection of SID files including metadata attributing composer
  and release date, all in a machine readable format.

  \subsection{Machine code and original hardware}
  Given the lack of built in sound software in the Commodore 64, the
  SID chip can only be fully utilized with 6502 machine code, and the
  chip exhibits significant performance differences (see following)
  even within units of the same model number and revision.  While
  several software and hardware emulations of the SID chip exist, the
  behavior original hardware has proven difficult to reproduce exactly
  and emulator defects continue to be discovered.  Therefore analysis
  must include not only methods to work with original hardware, but
  original machine code as well.

  \subsection{Demoscene}

  \subsection{Generative synthesis}
  There is recent work in generative synthesis, for example in
  predicting new patch parameters or waveforms for modular
  synthesizers.  While this work involves machine learning prediction
  of audio samples (unlike this research which involves the
  identification and prediction of SID register state, which leads to
  audio samples), there is a shared focus on the role of patch
  parameter prediction.  A research outcome therefore may be
  a SID generative synthesiser tool that permutes initial
  SID register state in a creative direction guided by a composer
  (for example, altering a snare drum patch over time).

  \subsection{Role of machine learning}
  The field of machine learning has made rapid advances in the past
  few years and it is anticipated that it will continue to
  rapidly. Therefore, the research will be divided into two loosely
  coupled logistical tracks, musicological research and tool
  development.

  Tool development will be based on machine learning and
  analysis frameworks such as pyTorch and Pandas, so that new
  capabilities can be rapidly integrated with research as they become
  available. As musicology is the primary focus of the research,
  use of machine learning technologies will be constrained to
  accessible frameworks to manage time and resources. Nonetheless,
  the pyTorch project has maintained an aggressive release cadence
  (at least once per quarter year) so new technology may not
  be out of reach for long.

  \section{Methodology}

  \subsection{Register logging}
  The fundamental data upon which the analysis will be based, is
  changes in state (register modifications) of the SID chip The
  approach will be to use decompilation tools that intercept all calls
  between a machine language program (a performance) and an emulated
  SID chip. A performance can there for be represented as a time ordered
  list of calls, where each call is defined as a 4-tuple:

  (T, C, R, V)

  Where T is the elapsed time in machine cycles (approximately
  microseconds) since the last call was made, C is the SID chip number
  (if more than one SID chip is used), R is a SID chip memory
  register, and V is value to put in the register (R and V are both 8
  bit values, whereas T may range typically range from 1-2 to 10-20
  thousand.

  The sequence and content of the calls contain the ``patch''
  information (how a voice is being manipulated - for example
  switching from a pulse waveform to a noise waveform within 20ms, to
  produce a percussive sound, as well as score information over a
  longer time scale (for repeated subsequences producing percussive
  sounds at regular intervals).

  \subsection{VICE emulator logging modifications}
  The VICE emulator provides a debugging ``dump'' function that
  produces logs in the above format, except for the chip number
  (VICE is modified to add this).  The output is postprocessed
  to remove redundant state (see below).

  \subsection{Sequence segmentation}
  The fundamental technique upon which the analysis will be performed,
  is the segmentation of sub sequences of SID register calls at
  enumerated intervals within the sequence accomplishing an entire
  performance. Then, identifying repeated sequences and variations and
  comparing sequences across thousands of performances.

  From a first principles perspective, there are several anticipated
  stages in segmentation. It assumed that for a given SID chip
  (emulated or otherwise) initialized to the same state, that the same
  sequence of instructions will result in the same output. This
  assumption will need to be verified throughout as if not correct
  would invalidate comparison. It is also expected that a set of
  different sequences may result in the same audio output, so there
  may be a many to one relationship for a given audio output.

  \subsection{Redundant state}
  It follows also that there may be sequences that produce no change
  in audio output (for example, repeatedly writing the same value to a
  frequency register, or writing a value to a register with less than
  8 significant bits). These sequences can be eliminated because by
  definition their significance is inaudible.

  Depending on the machine code making the SID register calls, there
  may be variation in the time taken between individual items in a
  sequence (for example, one program might take longer to calculate a
  new frequency value than another using a different algorithm, even
  though both programs end up calculating the same value). This
  difference may or may not be audible. A threshold will have to be
  defined (for example, if SID register changes are accomplished
  within one audio sample time at 44.1kHz no difference would be
  observed).  Nonetheless, verification of the significance (or non
  significance) of small differences in timing between the same
  register calls will be required.

  \subsection{Voice multiplexing}
  The SID chip has 3 voices, which can be configured in pairs for some
  FM effects. A given voice may only be paired with a fixed choice of
  one other (for example, voices 1 and 3 are paired). Due to the very
  small number of voices available composers made extensive use of
  multiplexing, for example executing a percussion sound sequence on
  voice 1, then executing a simple pulse wave on voice 1 while
  executing the same percussion sound sequence on voice 2. It is
  assumed that all single voices are interchangeable, and that all
  voice pairs are interchangeable, assumptions that must be verified.

  Aside from the voices, the SID chip has programmable filters and a 4
  bit volume register. All voices are affected by the volume register
  and can be selectively routed to the filters. There is therefore
  another kind of sequence state to be considered, individual voice
  states paired with a specific filter and volume state. These
  combinations must be modeled for comparison.

  \subsection{ADSR envelope bugs}

  \subsection{Oscillator 3 feedback}

  \subsection{High/low data rate}

  \section{Preliminary work}

  \subsection{Decompilation}

  \subsection{Classification models}

  \subsection{Generative models}

  \section{Thesis structure}

  \subsection{Introduction}

  \subsection{Methodology}

  \subsection{Evolution of SID sample playback}

  \subsection{SID patch model}

  \subsection{SID patch difference metrics}

  \subsection{Visualizing complex and patch dessemination}

  \subsection{Patch programming classification}

  \subsection{Dessimenation}

  \subsection{Tools and datasets}

\section{Novel contributions and conclusions}

The tools and techniques may be applicable to synthesis platforms
beyond the Commodore 64 (for example, it may be possible to parse
Ableton Live set files at scale, attributing innovation in certain
patch configurations to composers, or to programmatically generate new
set files with machine learning tools).


%% \subsection{Formatting}

%% All figures and tables that are part of the proposal should fit the page limit. A sample figure is presented in Figure~\ref{fig:fig1}. A sample table that includes how to cite references is presented in Table~\ref{tbl:tbl1}. We do not allow for submission of additional material such as appendices and supplementary materials like data or code.

%% You can use the \texttt{Introduction} section to:


\begin{table*}
        \centering
        \begin{tabular}{cc}
                \hline
                \textbf{Citation format} & \textbf{Citation command} \\
                \hline
                \citet{APA:83} & \textbackslash{}citet{} \\
                \citep{APA:83} & \textbackslash{}citep{} \\
                \hline
        \end{tabular}
        \caption{This is sample table with full page width.}
        \label{tbl:tbl1}
\end{table*}

\begin{figure}[H]
    \centering
        \includegraphics[width=\columnwidth]{example-image}
        \caption{This is a sample figure.}
        \label{fig:fig1}
\end{figure}

\end{multicols*}

\clearpage

\bibliography{nzsm-phd-proposal}
\bibliographystyle{plainnat}

\end{document}

% LocalWords:  PCM timeline HVSC Dessimenation Ableton APA citet nzsm
% LocalWords:  programmatically citep phd ADSR
